(my_tensorflow) masha@masha-ThinkPad-X1-Extreme:~/Desktop/spans_10_10$ python train1.py 
WARNING: randomly initializing word vectors
/home/masha/anaconda3/envs/my_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Initializing tf session
2018-11-25 01:41:03.874367: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
training
Epoch 1 out of 15
186/205 [==========================>...] - ETA: 5s - train loss: 31.75942018-11-25 01:42:03.097814: W tensorflow/core/framework/allocator.cc:122] Allocation of 27216000 exceeds 10% of system memory.
2018-11-25 01:42:03.102337: W tensorflow/core/framework/allocator.cc:122] Allocation of 27216000 exceeds 10% of system memory.
2018-11-25 01:42:03.102341: W tensorflow/core/framework/allocator.cc:122] Allocation of 27216000 exceeds 10% of system memory.
2018-11-25 01:42:03.136185: W tensorflow/core/framework/allocator.cc:122] Allocation of 27216000 exceeds 10% of system memory.
2018-11-25 01:42:03.967233: W tensorflow/core/framework/allocator.cc:122] Allocation of 27216000 exceeds 10% of system memory.
205/205 [==============================] - 68s - train loss: 32.1118    
i: f1=0.38  p=0.41  r=0.35
o: f1=0.35  p=0.74  r=0.23
p: f1=0.52  p=0.65  r=0.43
N: f1=0.83  p=0.76  r=0.92
macro score 
 {'f1': 0.5190650205376854, 'p': 0.6402687144163878, 'r': 0.48113742402637405} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[  8516    143   1221  14795]
 [  2928   7730   1059  21778]
 [  1931    178  13160  15347]
 [  7301   2364   4923 165071]]
f1 0.52 - p 0.64 - r 0.48
- new best score!
Epoch 2 out of 15
205/205 [==============================] - 68s - train loss: 16.7077     
i: f1=0.46  p=0.62  r=0.36
o: f1=0.56  p=0.64  r=0.50
p: f1=0.61  p=0.62  r=0.60
N: f1=0.84  p=0.80  r=0.89
macro score 
 {'f1': 0.616196791151015, 'p': 0.6703043205581664, 'r': 0.5850418203469125} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[  8895    577   1738  13465]
 [   605  16582   1633  14675]
 [   508    375  18340  11393]
 [  4383   8219   7953 159104]]
f1 0.62 - p 0.67 - r 0.59
- new best score!
Epoch 3 out of 15
205/205 [==============================] - 68s - train loss: 10.9938     
i: f1=0.48  p=0.61  r=0.39
o: f1=0.57  p=0.64  r=0.52
p: f1=0.61  p=0.52  r=0.74
N: f1=0.83  p=0.83  r=0.84
macro score 
 {'f1': 0.6230669064187526, 'p': 0.648652657413891, 'r': 0.6220576866221854} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[  9732    591   3254  11098]
 [   593  17334   2302  13266]
 [   468    367  22669   7112]
 [  5086   8980  15419 150174]]
f1 0.62 - p 0.65 - r 0.62
- new best score!
Epoch 4 out of 15
205/205 [==============================] - 69s - train loss: 8.0160     
i: f1=0.52  p=0.57  r=0.48
o: f1=0.58  p=0.60  r=0.56
p: f1=0.62  p=0.53  r=0.74
N: f1=0.83  p=0.84  r=0.81
macro score 
 {'f1': 0.6360922555895252, 'p': 0.6353948971113111, 'r': 0.6482909160434426} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 11774    731   2960   9210]
 [   923  18744   2153  11675]
 [   615    467  22772   6762]
 [  7385  11191  15092 145991]]
f1 0.64 - p 0.64 - r 0.65
- new best score!
Epoch 5 out of 15
205/205 [==============================] - 69s - train loss: 6.6567     
i: f1=0.53  p=0.56  r=0.50
o: f1=0.59  p=0.60  r=0.58
p: f1=0.62  p=0.55  r=0.72
N: f1=0.83  p=0.84  r=0.81
macro score 
 {'f1': 0.6431908287221767, 'p': 0.63818378153549, 'r': 0.6551704146678251} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12333    874   2617   8851]
 [   723  19594   1722  11456]
 [   771    599  22123   7123]
 [  8121  11618  13806 146114]]
f1 0.64 - p 0.64 - r 0.66
- new best score!
Epoch 6 out of 15
205/205 [==============================] - 69s - train loss: 6.1212     
i: f1=0.55  p=0.54  r=0.55
o: f1=0.60  p=0.57  r=0.63
p: f1=0.64  p=0.58  r=0.70
N: f1=0.83  p=0.85  r=0.80
macro score 
 {'f1': 0.6512475160058275, 'p': 0.6357208532113218, 'r': 0.6703913314440925} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 13632   1101   1868   8074]
 [   839  21073   1580  10003]
 [  1157    719  21355   7385]
 [  9699  14010  11782 144168]]
f1 0.65 - p 0.64 - r 0.67
- new best score!
Epoch 7 out of 15
205/205 [==============================] - 69s - train loss: 5.1247     
i: f1=0.54  p=0.56  r=0.52
o: f1=0.54  p=0.69  r=0.45
p: f1=0.64  p=0.65  r=0.64
N: f1=0.85  p=0.81  r=0.88
macro score 
 {'f1': 0.6431459314153125, 'p': 0.6796695711365286, 'r': 0.6206668451407423} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12894    483   1446   9852]
 [   908  14937   1166  16484]
 [   921    404  19447   9844]
 [  8231   5864   7648 157916]]
f1 0.64 - p 0.68 - r 0.62
Epoch 8 out of 15
205/205 [==============================] - 68s - train loss: 4.2345     
i: f1=0.54  p=0.57  r=0.51
o: f1=0.55  p=0.69  r=0.46
p: f1=0.64  p=0.66  r=0.62
N: f1=0.85  p=0.81  r=0.88
macro score 
 {'f1': 0.643974696690356, 'p': 0.684261589289027, 'r': 0.6174718542352058} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12478    515   1298  10384]
 [   748  15351   1123  16273]
 [   963    380  19043  10230]
 [  7597   6020   7243 158799]]
f1 0.64 - p 0.68 - r 0.62
Epoch 9 out of 15
205/205 [==============================] - 69s - train loss: 3.4278     
i: f1=0.54  p=0.59  r=0.50
o: f1=0.58  p=0.67  r=0.51
p: f1=0.65  p=0.67  r=0.63
N: f1=0.85  p=0.82  r=0.88
macro score 
 {'f1': 0.6535595151655049, 'p': 0.6863686424807662, 'r': 0.6290767371094452} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12260    660   1465  10290]
 [   628  17051   1068  14748]
 [   787    462  19289  10078]
 [  6956   7363   7176 158164]]
f1 0.65 - p 0.69 - r 0.63
- new best score!
Epoch 10 out of 15
205/205 [==============================] - 68s - train loss: 2.9639     
i: f1=0.53  p=0.63  r=0.46
o: f1=0.60  p=0.62  r=0.58
p: f1=0.64  p=0.72  r=0.57
N: f1=0.85  p=0.81  r=0.88
macro score 
 {'f1': 0.6533173424499146, 'p': 0.6968429924478174, 'r': 0.622349863665697} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 11275    951   1125  11324]
 [   410  19304    765  13016]
 [   619    640  17491  11866]
 [  5549  10343   4799 158968]]
f1 0.65 - p 0.70 - r 0.62
Epoch 11 out of 15
205/205 [==============================] - 71s - train loss: 2.5993     
i: f1=0.52  p=0.65  r=0.44
o: f1=0.56  p=0.67  r=0.49
p: f1=0.62  p=0.74  r=0.54
N: f1=0.85  p=0.80  r=0.91
macro score 
 {'f1': 0.6393599306587253, 'p': 0.7125991249919419, 'r': 0.593034956323534} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 10854    663   1033  12125]
 [   410  16295    723  16067]
 [   510    450  16383  13273]
 [  5010   6941   4100 163608]]
f1 0.64 - p 0.71 - r 0.59
Epoch 12 out of 15
205/205 [==============================] - 68s - train loss: 2.2325     
i: f1=0.51  p=0.64  r=0.43
o: f1=0.57  p=0.67  r=0.49
p: f1=0.62  p=0.74  r=0.54
N: f1=0.85  p=0.80  r=0.91
macro score 
 {'f1': 0.6390381469328251, 'p': 0.7127777967202035, 'r': 0.5926674942425589} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 10559    619   1072  12425]
 [   423  16434    751  15887]
 [   500    432  16563  13121]
 [  4898   6952   4119 163690]]
f1 0.64 - p 0.71 - r 0.59
- early stopping 3 epochs without improvement


eval on dev
i: f1=0.54  p=0.59  r=0.50
o: f1=0.58  p=0.67  r=0.51
p: f1=0.65  p=0.67  r=0.63
N: f1=0.85  p=0.82  r=0.88
macro score 
 {'f1': 0.6535595151655049, 'p': 0.6863686424807662, 'r': 0.6290767371094452} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12260    660   1465  10290]
 [   628  17051   1068  14748]
 [   787    462  19289  10078]
 [  6956   7363   7176 158164]]
(my_tensorflow) masha@masha-ThinkPad-X1-Extreme:~/Desktop/spans_10_10$ python evaluate1.py 

accidental rerun
22 2 2 .
i: f1=0.53  p=0.61  r=0.46
o: f1=0.51  p=0.73  r=0.39
p: f1=0.64  p=0.73  r=0.57
N: f1=0.85  p=0.79  r=0.92
macro score 
 {'f1': 0.6317425535337389, 'p': 0.7166048509256089, 'r': 0.5849370856165093} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 11361    342   1133  11839]
 [   529  13148    778  19040]
 [   645    319  17408  12244]
 [  6007   4230   4460 164962]]
f1 0.63 - p 0.72 - r 0.58

22 2 2 .
i: f1=0.53  p=0.58  r=0.49
o: f1=0.60  p=0.63  r=0.57
p: f1=0.65  p=0.70  r=0.61
N: f1=0.85  p=0.82  r=0.87
macro score 
 {'f1': 0.6566454943929014, 'p': 0.6829416921850496, 'r': 0.6349704014738324} 

Confusion matrix: 
 rows: true labels (the order is the same as in /data/tags.txt) 
 columns: predicted labels (the order is the same as in /data/tags.txt)
[[ 12073    705   1241  10656]
 [   624  19064    929  12878]
 [   944    570  18639  10463]
 [  7289   9785   5807 156778]]





