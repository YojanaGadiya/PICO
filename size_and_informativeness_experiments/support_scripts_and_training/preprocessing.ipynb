{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dictionary containing sentence embeddings (averaged word embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id_dict = pickle.load(open(\"sent_id_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = pickle.load(open (\"pubmed_embed_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40822, 200)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(sent_id_dict),embedding_len), dtype=float)\n",
    "#print(len(sent_id_dict))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "UNK = np.random.uniform(low=-1.0, high=1.0, size=(200,) )\n",
    "NUM = np.random.uniform(low=-1.0, high=1.0, size=(200,) )\n",
    "print(embed_dict['.'].shape)\n",
    "print(UNK.shape)\n",
    "print(NUM.shape)\n",
    "embed_dict['UNK'] = UNK\n",
    "embed_dict['-UNK-'] = UNK\n",
    "embed_dict['NUM'] = NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40822/40822 [00:06<00:00, 6557.11it/s]\n"
     ]
    }
   ],
   "source": [
    "tok_sent_list = []\n",
    "for sent in tqdm(sent_id_dict):\n",
    "    tok_sent = word_tokenize(sent)\n",
    "    new_tok_sent = []\n",
    "    for word in tok_sent: \n",
    "        if word.isdigit():\n",
    "            #print(word)\n",
    "            new_tok_sent.append('NUM')\n",
    "        elif word in embed_dict:\n",
    "            new_tok_sent.append(word)\n",
    "        else:\n",
    "            new_tok_sent.append('UNK')\n",
    "    tok_sent_list.append(new_tok_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40822\n"
     ]
    }
   ],
   "source": [
    "print(len(tok_sent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40822/40822 [00:22<00:00, 1835.37it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_sent_id_dict = {}\n",
    "sent_embed_list = []\n",
    "for sent in tqdm(tok_sent_list):\n",
    "    index = tok_sent_list.index(sent)\n",
    "    sent_embed = np.zeros(embedding_len)\n",
    "\n",
    "    for word in sent:\n",
    "        word_embed = embed_dict[word]\n",
    "        sent_embed = sent_embed + word_embed\n",
    "    sent_embed = sent_embed/len(tok_sent)\n",
    "    X[index] = X[index] + sent_embed\n",
    "    string = ' '.join(str(x) for x in sent_embed)\n",
    "    sent_embed_list.append(sent_embed)\n",
    "    encoded_sent_id_dict[string] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(encoded_sent_id_dict, open (\"encoded_sent_id_dict.p\", \"wb\"))\n",
    "pickle.dump(sent_embed_list, open (\"sent_embed_list.p\", \"wb\"))\n",
    "pickle.dump(tok_sent_list, open (\"tok_sent_list.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
